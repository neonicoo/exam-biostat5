---
title: "Colle_4BiM_2020_biostats5"
author: "Nicolas Mendiboure 4BiM"
date: "29/01/2021"
geometry: margin=2cm
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r clean variables}
rm(list=ls())
```

```{r datas loading}
goodlife <- read.csv("./good_life.txt", sep = "\t", header = TRUE, dec = ",")
continent <- goodlife$continent
region <- goodlife$region_monde
pays <- goodlife$pays
co2 <- goodlife$CO2
eau <- goodlife$eau
sanitaire <- as.factor(goodlife$sanitaire)
democratie <- as.factor(goodlife$democratie)
```

### Q1. Les variables « sanitaire » et « democratie » sont-elles dépendantes ? Justifier votre réponse par un test approprié et exprimer la conclusion avec une phrase complète.

```{r lm1}
num_sanitaire <- as.numeric(sanitaire)
num_democratie <- as.numeric(democratie)
tab <- table(num_sanitaire,num_democratie)
chisq.test(tab)
```
On fait une table de contingence que l'on nomme *tab* avec les effectifs observés pour nos 2 variables « sanitaire » et « democratie ». Les deux variables sont converties préalablement en variables numériques. On effectue un test de chisq2 en comparant nos effectifs observés à nos éffectifs théoriques.

H0 : Les variables « sanitaire » et « democratie » sont idépendantes;

H1 : Les variables « sanitaire » et « democratie » sont dépendantes.

On effectue le test du chisq2 et nous obtenons une p-value de 6.3e- donc très significative, ce qui nous permet de rejeter H0.
Il existe une relation qui lie la variable « sanitaire » à la variable  « democratie ». Autrement dit, l'état sanitaire varie lorsque que le niveau de démocratie varie.

Remarque : Il faut faire attention à la condition d'utilisation pour le test du chisq2. Celle ci dit qu'il faut vérifier que 80% des classes doivent avoir un effectif théorique supérieure ou égale à 5. 

On peut vérifier cela de la façon suivante :

```{r khideux expected}
chisq.test(tab)$expected
```

La condition est donc bien vérifiée. Dans le cas contraire il faudrait utiliser le test exact de *fisher* comme ci dessous :

```{r fisher.test}
fisher.test(tab)
```

### Q2. Décrire le plan d’expérience correspondant à l’analyse demandée.

```{r Q2}
xtabs(~ sanitaire + democratie)
```
Grâce à la fonction xtabs ci-dessus, on voit qu'il s'agit d'un plan d'expérience factoriel croisé à deux facteurs (democratie 3 niveaux et sanitaire  niveaux) car pour chaque couple (*sanitaire[i]*, *democratie[j]*) nous avons des mesures de CO2. Le plan est également complet car nous n'avons pas de case vide, mais il est déséquilibré car nous n'avons pas le même nombre de mesures par case. Il s'agit d'un modèle aléatoire car nos deux facteurs *sanitaire* et *democratie* sont aléatoire, les pays ont été choisis volontairement et sont fixes mais les variables qui caractérisent ces pays sont quant à elles aléatoires.

### Q3. Comparer les émissions de CO2 des pays en fonction de leur niveau de démocratie et de leur état sanitaire par un modèle (lm1) et réaliser les tests appropriés ?

Dans la question 1 nous avons vu que nous devions rejeter l'hypothèse disant que les variables *sanitaire* et *democratie* étaient indépendante. Nous savons donc qu'il existe une interaction entre ces 2 variables, mais nous ne savons pas si cette interaction a un effet significatif sur les émissions de C02. On peut tout d'abord commencer par donner un aperçu de cette interaction afin d'avoir un idée : 

```{r interaction plot}
interaction.plot(sanitaire, democratie, co2, col = 2:4)
```


Nous allons maintenant construire un premier modèle linéaire qui prendra en compte cette interaction :

```{r Q3}
lm1 <- lm(co2 ~ democratie * sanitaire )
anova(lm1)
```
Après avoir fait un test d'anova on se rend compte que le terme d'interaction n'est pas significatif (p-value = 0.3). Ce tableau permet également de tester les effets du niveau de démocratie et de l'état sanitaire sur l'émission de CO2.

Les effets *democratie* et *sanitaire* sont tous les deux très significatif.

On a vu que le terme d'interaction n'était pas significatif, nous pouvons donc l'enlever de notre modèle lm1. Ce raisonnement n'est toutefois pas le meilleur car si l'on veut tester les termes par rapport au terme d'interaction, celui-ci ayant été retiré se trouvera dans la résiduelle.

```{r new lm1}
lm1b <- lm(co2~ democratie + sanitaire)
summary(lm1b)
```

Grâce au *summary* on voit que les effets de  *democratiefort* et de *sanitairehaut* haut diffèrent de *democratiebas* et *sanitairebas*. Il est possible de faire un contraste pour tester *democratiefort* et *democratiemoyen* :

```{r contrast}
contrasts(democratie) #par défaut
contrasts(democratie) <- contr.treatment(3, base = 2)
contrasts(democratie) # democratiefort passe en référence (dans l'intercept)
lm1b <- lm(co2~democratie+sanitaire)
summary(lm1b)
```
On voit donc qu'il y a une différence de moyenne d'émission de co2 entre *democratiefort* (maintenant dans l'intercept) et *democratiemoyen*.

### Q4. Ecrire le modèle lm1 sous la forme d’une équation et interpréter les termes significatifs.

L'équation du modèle s'écrit :

$lm1b = \beta_0 + \beta_1 \times I[democratiefort] + \beta_2 \times I[democratiemoyen] + \beta_3 \times I[sanitairehaut]$

-$\beta_0$ correspond à l'intercept, c'est à dire à la valeur prédite d'émission de co2 pour un niveau de democratie faible et un état sanitaire bas. Cette valeur n'est pas significative ;

-$\beta_1$ correspond à la différence de moyenne d'emission de co2 pour pour un niveau de démocratie fort et un niveau de democratie faible, pour même état sanitaire bas. Ce coefficient est significatif ;

-$\beta_2$ correspond à la différence de moyenne d'emission de co2 pour pour un niveau de démocratie moyen et un niveau de democratie faible, pour un même état sanitaire bas. Ce coefficient n'est pas significatif ;

-$\beta_3$ correspond à la différence de moyenne d'emission de co2 pour pour un état sanitaire haut et un état sanitaire bas, pour un même niveau de démocratie faible. Ce coefficient est très significatif.


### Q5. Changer l’ordre d’introduction des variables explicatives de votre modèle ? Quels effets observez-vous sur votre analyse (lm2) et pourquoi ?

```{r q5}
lm2 <- lm(co2~sanitaire + democratie)
anova(lm2)
```
Lorsque l'on compare les tests anova de lm1b et lm2 on remarque que la somme des carrés des écarts résiduels reste la même, et la somme des carrés des écarts des 2 facteurs reste également identique :

```{r sum mean sq}
(385.51 + 313.52) == (605.24 + 93.79) # les Mean Sq sont égaux
```
En effet la somme des carrés des écarts totale est la même quel que soit le modèle, puisqu’elle correspond à la somme des carrés des écarts entre valeurs observées et moyenne générale : $SCE_T = SCE_M + SCE_R$ . La $SCE_R$ étant identique pour les trois modèles, ceci explique pourquoi la $SCE_M$ est également identique.

Par contre, on observe des différences entre les sommes des carrés des écarts expliqués par chacun des facteurs
d’un modèle à l’autre. Néanmoins dans les 2 modèles, les deux facteurs sont significatifs. Les sommes des carrés ne sont pas identiques car nous avons un plan déséquilibré, ainsi les décompositions ne sont pas indépendantes.

### Q6. Proposer une solution pour avoir des estimations correctes de votre décomposition de la variance et refaire les conclusions de l’analyse.

Une solution pour avoir des estimations correctes de notre décomôsition de la variance serait de transformer notre plan factoriel déséquilibré en plan équilibré. Il faudrait avoir dans chaque case le même nombre de répétition, à savoir le nombre de répétitions le plus faible que nous avons dans notre plan déséquilibré, c'est à dire 7. Ainsi on passerait de 114 mesures à 42 mesures(3 democratie * 2 sanitaire * 7 répétitions ), les tests perdront donc malheureusement de la puissance. 


On pourrait construire un nouveau modèle *aov()* qui cette fois ci prendrait en compte un terme d'erreur porté par l'interaction. Les effets aléatoires doivent être testés par rapport au terme d'intéraction qui inclue à la fois l'erreur pure et l'intéraction.

```{r q6}
lm3 <- aov(co2~democratie+sanitaire+Error(democratie:sanitaire))
summary(lm3)
```
Par ailleurs il es facile de retrouver ces p-values avec notre modèle lm1 ( avec interaction ) initial. 

```{r estimation effet}
1-pf((192.755/8.142), 2, 2) #test de F pour l'effet democratie
1-pf((313.522/8.142), 1, 2) #test de F pour l'effet sanitaire 
```

On peut également estimer la contribution à la variabilité pour nos 2 facteurs aléatoires.

```{r estimations variances}
sqrt((192.755 - 6.786)/2) #sigma_democratie
sqrt((313.522 - 6.786)/3) #sigma_sanitaire
sqrt(6.786) #sigma_residuelles
```
Ainsi on peut on peur dire qu'il y a à la fois un effet democratie et aussi un effet sanitaire.

### Q7. Vérifier les hypothèses associées au premier modèle (lm1) et décrire les problèmes associés.

Les hypothèses à vérifier sont l'égalité des variances entre les différents groupes, la normalité des distributions par groupe, on suppose que les mesures sont indépendantes car effectuées sur des pays différents et qu'il n'y a pas de points aberrants. Enfin on suppose l'existence d'une relation réelle entre l'émission de CO2 et les niveaux de démocraties ainsi que les états sanitaires des pays.

```{r hypothèses q7}
par(mfrow = c(2, 2))
plot(lm1)
```
Sur le premier graphique (haut gauche) on voit une légère forme en 'cloche' pour les résidus, de plus l'espérance des résidus est proche de 0 mais n'est pas nulle. ON peut alors se demander si le modèle est bien adapté ? 

Sur le graphique en haut à droite, là aussi il est difficile de dire si les résidus suivent une li normale ou non, le mieu est de faire un test de normalité, *shapiro-wilk* par exemple :

```{r shapiro-wilk}
shapiro.test(residuals(lm1))
```
On a une p-value très significative qui nous permet de rejeter H0 : les résidus sont normalement distribués.

Troisième graphique (bas gauche) concernant les variances des résidus pour chaque combinaison de niveau de démocratie et d'état sanitaire. Là aussi il est difficile de conclure à une variance constante des résidus avec le graphe car on peut discerner une légère forme constituée de 2 pentes. On va donc effectuer une test de *bartlett* :

```{r bartlett.test}
bartlett.test(residuals(lm1), interaction(democratie, sanitaire))
```
La p-value est très faible donc on rejet l'hypothèse nulle de variance constante des résidus. 

Sur le 4ème graphique (bas droite) on voit que les points 33, 35 et 38 se démarque un peu plus que les autres, mais gardent une distance de Cook inférieure à 0.5, donc nous pouvons dire qu'il n'y a pas de valeur aberrante (outlier).

On peut également vérifier cette dernière hypothèse avec le plot suivant qui est peut être plus clair :

```{r cook}
par(mfrow=c(1,1))
plot(lm1,4)
```

En conclusion, ces hypothèses nous permettent de dire que le modèle lm1 n'est pas le modèle le plus adapté pour notre analyse. 

### Q8. On propose le code R ci-dessous. Expliquer ce qui est fait et comment peut-ont interpréter les 3 sorties numériques finales ?

```{r code q8}
F = matrix(0, nc = 4, nr = 1000)
for (i in 1:1000) {
  CO2_sim = sample(x = co2,
                   size = length(co2),
                   replace = FALSE)
  lm_temp = lm(CO2_sim ~ sanitaire * democratie)
  F[i, ] = anova(lm_temp)$"F value"
}
sum(F[, 1] > anova(lm1)$"F value"[1]) / 1000
sum(F[, 2] > anova(lm1)$"F value"[2]) / 1000
sum(F[, 3] > anova(lm1)$"F value"[3]) / 1000
```

Graphiquement cela donnerait :

Remarque : Sur les histogrammes on obtient des "formes" de loi de chisq2 ou loi de Fisher. Attention toutefois rien ne dit qu'il s'agit réellement de l'une ou l'autre de ces lois.

```{r histo}
par(mfrow=c(1,3))
hist(F[,1], col = 4) ; abline(v = anova(lm1)$"F value"[1], col = 'red')
hist(F[, 2], col = 5) ; abline(v = anova(lm1)$"F value"[2], col = 'red')
hist(F[,3], col = 3) ; abline(v = anova(lm1)$"F value"[3], col = 'red')
```

Avec ce code nous avons réalisé un test de simulation par rééchantillonage et permutation. Nous avons fait 1000 simulations dans lesquelles nous avons permuté aléatoirement et sans remise les 114 mesures d'émissions de CO2. ENsuite nous avons réalisé 1000 modèles linaire *lm* semblable au modèle *lm1*, c'est à dire que nous retrouvons nos trois termes : (*sanitaire*, *democratie*, *sanitaire:democratie*). À chaque simulation nous stockons dans une matrice *F* (1000 par 4) les F-values issus des tests anova.

Les trois sorties comparent le nombre de fois sur les 1000 simulations nous obtenons une F-value supérieure à celle des facteurs respectifs {1, 2, 3} dans le modèle lm1. POur les facteurs 1 et 2 nous obtenons 0, cela se vérifie sur les histogrammes où l'on aperçois même pas la droite verticale correspondant à la F-value des facteurs pour un anova(lm1).

Pour le facteur 3 nous obtenons un score de 0.3 environ. Ces simulations visent à confirmer les effets aléatoires des facteurs sanitaire et democratie. En effet le fait d'avoir permuté les mesures de CO2 et les scores obtenus pour les facteurs 1 et 2 montrent bien qu'il existe un réel lien entre l'émission de CO2 et le niveau de démocratie du pays ainsi que l'état sanitaire de celui ci. L'interaction des deux facteurs quant à elle n'affecte pas ces mesures, c'est pour cela que nous avons une score pour le facteur (d'interaction) 3 proche de la p-value du *anova(lm1)*. 

### Q9. On se propose de transformer la variable CO2 en ln(CO2), refaire l’analyse avec la variable transformée et refaire les conclusions.

```{r q9}
logCO2 <- log(co2)
lm4 <- lm(logCO2 ~ democratie*sanitaire)
```

On vérifie rapidement les hypothèses associées à ce nouveau modèle lm4 (sans détailler ici)
```{r hypotheses lm4}
par(mfrow = c(2,2))
plot(lm4)
shapiro.test(residuals(lm4)) # on ne rejete pas H0
bartlett.test(residuals(lm4), democratie)
bartlett.test(residuals(lm4), sanitaire) # => on rejete H0
par(mfrow = c(1,1))
plot(lm4, 4)
```

A priori les résidus semblent cette fois ci suivre une loi normale d'espérance nulle. Cependant nous n'avons toujours pas d'homogénéité des variances. Le modèle est un peu plus adapté que lm1 mais le soucis d'homoscédasticité persiste. Les distances de cooks sont également moins élévées.

```{r anova lm4}
anova(lm4)
```
D'après l'anova de *lm4*, les effets democratie et sanitaire sont encore plus significatifs qu'avec le modèle *lm1*.

```{r simulation avec logCO2}
Fb = matrix(0, nc = 4, nr = 1000)
for (i in 1:1000) {
  logCO2_sim = sample(x = logCO2,
                   size = length(logCO2),
                   replace = FALSE)
  lm_temp = lm(logCO2_sim ~ sanitaire * democratie)
  Fb[i, ] = anova(lm_temp)$"F value"
}
sum(Fb[, 1] > anova(lm4)$"F value"[1]) / 1000
sum(Fb[, 2] > anova(lm4)$"F value"[2]) / 1000
sum(Fb[, 3] > anova(lm4)$"F value"[3]) / 1000
```
En refaisant la simulation mais avec cette fois - ci logCO2, on retombe sur les mêmes résultats, qui est est cohérent ave l'anova fait juste au dessus.

### Q10. En fonction des différents modèles et des analyses réalisées jusque là, discuter de la robustesse de l’anova en fonction des conditions d’application du test.



### Q11. Les variables consommation d’eau et émission de CO2 sont-elles corrélées ?Faire un test paramétrique et un test non paramétrique et discuter de la différence de pvalue entre les deux tests.

Les tests paramétriques fonctionnent en supposant que les données que l’on a à disposition suivent un type de loi de distribution connu (en général la loi normale). Les tests non paramétriques ne font aucune hypothèse sur le type de loi de distribution des données. Ils se basent uniquement sur les propriétés numériques des échantillons.

Pour voir si nos variables eau et co2 sont corrélées nous pouvons utiliser le *cor.test*. Attention par défaut le *cor.test* utilise la méthode de "Pearson" fait l'hypothèse que notre échantillon suit une loi normale, c'est donc un test paramétrique. Nous pouvons donc faire une simulation par permutation afin de voir si nos variables suivent une loi normale :

```{r q11 norm}
library(nortest)

R <- rank(co2)
S <- rank(eau)
D <- sum((R-S)**2)

simulation=vector()
for (i in 1:1000) {
  R_sim=sample(R, length(R),replace=FALSE)
  S_sim=sample(S, length(S), replace = FALSE)
  simulation[i]=sum((R_sim - S_sim)**2)
}

hist(simulation, col = "aquamarine")
cvm.test(simulation)
```
L 'hypothèse que nos 2 variablse eau et co2 suivent une distribution bormale est donc vérifiée, nous pouvons utiliser un test paramétrique :

```{r test param}
cor.test(co2, eau, m = "pearson")
```
Nous obtenons une p-value $<< 0.05$, ce coefficient de corrélation de Pearson est donc bien significatif, nous pouvons rejeter H0 et dire que les variables eau et co2 sont corrélées. 

Remarque : Comme nous avons utilisé plusieurs test ici, nous aurions pu utiliser une correction de Bonférroni.

Nous aurions également pu faire un modèle linéaire comme ci-dessous, il s'agit également d'un test paramétrique, on remarque que la p-value est la même que dans le *cor.test*.

```{r lm q11}
anova(lm(co2~ eau))
```

Pour ce qui est de tester la corrélation avec un test non paramétrique, nous allons également utiliser la fonction *cor.test* avec des coefficient non parametriques cette fois ci. On peut par exemple utiliser les coefficients de corrélation de Kendall ou de Spearman : 

```{r test non param}
cor.test(co2, eau,  m="spearman") # attention aux ex-aequos 
cor.test(co2, eau, m="kendall")
```
Les p-values sont très faibles dans les 2 tests, la corrélation est donc significative et nous pouvons rejeter H0 dans les 2 cas.

On observe que la p-value du test non-paramétrique est très inférieure à celle du test paramétrique. De façon générale, les tests paramétriques sont plus puissants que les test non-paramétriques, c'est à dire qu'ils seront plus apte à rejeter H0, si le rejet est justifié. En revanche, un test non paramétrique sera lui plus robuste qu'un test paramétrique, c'est à dire qu'il pourra être utilisé dans un plus grand nombre de situations.


On s’intéresse maintenant à la géographie des émissions de CO2, avec les variables continent (considérée comme fixe) et region_monde (considérée ici, pour les besoins de l’exercice, comme aléatoire).

### Q12. Décrire le plan d’expérience qui intègre les variables continent et region_monde pour expliquer les émissions de CO2 (la variable pays ne sera pas considérée ici).

```{r q12}
tab2 <- table(continent, region); tab2
```


À présent le plan d'expérience qui intègre les variables *continent*, *co2* et *region* est un plan d'expérience factoriel hiérarchisé : *region* est nichée dans *continent*. C'est un plan mixte : *region* est aléatoire (9 niveaux) et continent est fixe (4 niveaux). Il n'y a pas le même nombre de répétition par couple (continent[i], region[j]), c'est donc déséquilibré.


### Q13. Construire le modèle adéquate pour estimer la part de variabilité apportée par les pays et par les régions du monde, puis comparez globalement les différents continents. Donner ces valeurs et justifiez vos conclusions par les tests appropriés. Si les fonctions utilisées ne permettent pas d’obtenir des tests pour les effets fixes (manque de données), vous le préciserez sur votre copie et ne chercherez pas à faire d’autres analyses


Commençons par un modèle *lm* classique. La variable *region* étant nichée dans *continent*, nous les introduirons dans l'ordre décroissant (conteneur + contenu ) dans le modèle.

```{r lm classiques}
lm5 <- lm(co2 ~ continent + region) # attention l'ordre est important 
anova(lm5)
```
Avec ce test d'anova nous ne pouvons regarder ici  que le niveau du facteur niché, à savoir région. Ainsi il y a des différences très significatives entre les régions de façon globale.

Maintenant essayons de regarder s'il existe un effet globale des continents. Pour cela nous allons construire un modèle qui comptabilisera la variabilité expliquée par l'effet région avec l'erreur pure dans la résidelle.


```{r aov lm6}
lm6 <- aov(co2 ~ continent + Error(region))
summary(lm6)
```
Ici on voit donc que l'effet continent n'est pas significatif sur l'émission de CO2 (p-value = 0.621). Par ailleurs la hiérarchisation de notre modèle coûte en puissance, ainsi la p-value du "niveau supérieur" est  beaucoup plus élevée. 


```{r libraries}
library(nlme)
library(lme4)
```

```{r dependance continent - region}
chisq.test(tab2)
```
On voit que les variables *region* et *continent* sont dépendantes par le test du chisq2. En réalité ce test est inutile car nous savons que *region* est subordonnée à *continent*, il est donc normale d'avoir une relation entre ces deux variables. 

Comme le modèle est mixte et hiérarchisé, nous allons utiliser un modèle *lme()* de la librairie *nlme*. Celui-ci est plus approprié à notre cas de figure qu'un modèle *lm()* classique.


```{r lm 5}
lm5 <- lme(fixed=co2~1+continent, random = list(continent=~1, region=~1))
summary(lm5)
coefficients(lm5)
```


```{r lm6}
lm6 <- lmer(co2~continent+(1|continent:region))
summary(lm6)
anova(lm6)
```

